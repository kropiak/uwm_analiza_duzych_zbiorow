# Przetwarzanie dużych zbiorów danych

### Semestr 2024/2025

## 0. Wstęp i wymagania techniczne.

Ekosystem istniejący na rynku wokół zagadnień Big Data jest ogromny, stąd prowadzący dokonał arbitralnego wyboru narzędzi, które zostaną zaprezentowane. Jednym z nich jest Apache Spark jako najczęściej wykorzystywane narzędzie przez inżynierów Big Data. Natywnym środowiskiem pracy tego narzędzia jest JVM i język scala, jednak ze względu na wielką popularność języka Python w kontekście data science coraz większa część funckjonalności poprzez odpowiednie API jest również dostępna z poziomu języka Python. Zajęcia będą koncentrowały się na wykorzystaniu tego właśnie języka programowania.

W trakcie zajęć przedstawione zostaną poniższe narzędzia:
* optymalizacja danych przetwarzanych za pomocą biblioteki pandas,
* biblioteka Dask,
* wprowadzenie do systemu Spark,
* PySpark
* formaty danych dla Big Data,
* bazy danych NoSQL,
* Apache Hadoop,
* Apache Kafka,
* wykorzystanie Apache Spark w rozproszonym ML.

W trakcie zajęć będzie wykorzystywany interpreter **Pythona w wersji 3.11.9** oraz głównie oprogramowanie **Jupyter Lab** z dostępem poprzez przeglądarkę internetową.
W późniejszej fazie zajęć, w zależności od możliwości, może pojawić się konieczność wykorzystania oprogramowania Docker.

## 1. Sylabus

TBA

## 2. Forma zajęć

Każdorazowo na zajęciach student otrzyma opisane przykłady wykorzystania danego narzędzia w formie pliku cyfrowego.
Prowadzący zaprezentuje sposób uruchomienia przykładów i wytłumaczy ich działanie. W każdym zestawie pojawią się zadania do samodzielnego wykonania bazujące na wcześniej zaprezentowanych przykładach.

## 3. Zaliczenie

Na zaliczenie składać się będą dwa elementy:
* wykonanie ćwiczeń przydzielonych w trakcie zajęć,
* wykonanie projektu zaliczeniowego.

Temat i zakres projektu zostanie przedstawiony na 2-3 spotkaniu.

## 4. Materiały

TBA



